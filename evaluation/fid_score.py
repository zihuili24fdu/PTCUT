"""
FID (FrÃ©chet Inception Distance) å›¾åƒè´¨é‡è¯„ä¼°å·¥å…·
ç”¨äºè¯„ä¼°éé…å¯¹æ•°æ®é›†çš„ç”Ÿæˆå›¾åƒè´¨é‡
FIDå€¼è¶Šå°è¡¨ç¤ºç”Ÿæˆå›¾åƒåˆ†å¸ƒè¶Šæ¥è¿‘çœŸå®å›¾åƒåˆ†å¸ƒ
"""

import os
import sys
from pathlib import Path
from typing import Optional
import warnings

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from PIL import Image

# ============== é…ç½®å‚æ•° ==============
# cut white2he white2masson
REAL_PATH = "/home/lzh/myCode/contrastive-unpaired-translation/datasets/new53_white2masson/test_latest/images/real_B"
FAKE_PATH = "/home/lzh/myCode/contrastive-unpaired-translation/datasets/new53_white2masson/test_latest/images/fake_B"
# CycleGAN white2he white2masson
REAL_PATH = "/home/lzh/myCode/pytorch-CycleGAN-and-pix2pix/datasets/new53_white2masson/test_latest/images_organized/real_B"
FAKE_PATH = "/home/lzh/myCode/pytorch-CycleGAN-and-pix2pix/datasets/new53_white2masson/test_latest/images_organized/fake_B"
# my white2he
REAL_PATH = "/home/lzh/myCode/awesome-virtual-staining/datasets/TTC1/test_latest/images/real_B"  
FAKE_PATH = "/home/lzh/myCode/awesome-virtual-staining/datasets/TTC1/test_latest/images/fake_B"  
# cut white2he
REAL_PATH = "/home/lzh/myCode/contrastive-unpaired-translation/datasets/mydatasets_CUT/test_latest/images/real_B" 
FAKE_PATH = "/home/lzh/myCode/contrastive-unpaired-translation/datasets/mydatasets_CUT/test_latest/images/fake_B" 
BATCH_SIZE = 50  # æ‰¹å¤„ç†å¤§å°
NUM_WORKERS = 4  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"  # ä½¿ç”¨çš„è®¾å¤‡
EXTS = ".png,.jpg,.jpeg,.tif,.tiff"  # åŒ¹é…çš„å›¾åƒæ‰©å±•å
DIMS = 2048  # InceptionV3ç‰¹å¾ç»´åº¦ (64, 192, 768, 2048)
# ======================================

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    from scipy import linalg
except ImportError:
    raise RuntimeError("âŒ è¯·å®‰è£… scipy: pip install scipy")

try:
    from tqdm import tqdm
except ImportError:
    raise RuntimeError("âŒ è¯·å®‰è£… tqdm: pip install tqdm")

try:
    from torchvision import models, transforms
except ImportError:
    raise RuntimeError("âŒ è¯·å®‰è£… torchvision: pip install torchvision")

warnings.filterwarnings('ignore')


class InceptionV3Feature(nn.Module):
    """
    ä½¿ç”¨é¢„è®­ç»ƒçš„InceptionV3æå–ç‰¹å¾
    æ”¯æŒå¤šä¸ªæ± åŒ–å±‚è¾“å‡º
    """
    
    def __init__(self, output_blocks=[3], resize_input=True, normalize_input=True):
        super().__init__()
        self.resize_input = resize_input
        self.normalize_input = normalize_input
        self.output_blocks = sorted(output_blocks)
        
        # åŠ è½½é¢„è®­ç»ƒçš„InceptionV3
        inception = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
        inception.eval()
        
        # æ„å»ºç‰¹å¾æå–å—
        self.blocks = nn.ModuleList()
        
        # Block 0: åˆ°ç¬¬ä¸€ä¸ªæ± åŒ–å±‚
        block0 = [
            inception.Conv2d_1a_3x3,
            inception.Conv2d_2a_3x3,
            inception.Conv2d_2b_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2)
        ]
        self.blocks.append(nn.Sequential(*block0))
        
        # Block 1: åˆ°ç¬¬äºŒä¸ªæ± åŒ–å±‚
        block1 = [
            inception.Conv2d_3b_1x1,
            inception.Conv2d_4a_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2)
        ]
        self.blocks.append(nn.Sequential(*block1))
        
        # Block 2: åˆ°è¾…åŠ©åˆ†ç±»å™¨
        block2 = [
            inception.Mixed_5b,
            inception.Mixed_5c,
            inception.Mixed_5d,
            inception.Mixed_6a,
            inception.Mixed_6b,
            inception.Mixed_6c,
            inception.Mixed_6d,
            inception.Mixed_6e,
        ]
        self.blocks.append(nn.Sequential(*block2))
        
        # Block 3: åˆ°æœ€ç»ˆæ± åŒ–å±‚ (2048ç»´ç‰¹å¾)
        block3 = [
            inception.Mixed_7a,
            inception.Mixed_7b,
            inception.Mixed_7c,
            nn.AdaptiveAvgPool2d(output_size=(1, 1))
        ]
        self.blocks.append(nn.Sequential(*block3))
        
        # å†»ç»“æ‰€æœ‰å‚æ•°
        for param in self.parameters():
            param.requires_grad = False
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # è°ƒæ•´è¾“å…¥å¤§å°åˆ° 299x299
        if self.resize_input:
            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)
        
        # å½’ä¸€åŒ–åˆ° [-1, 1]
        if self.normalize_input:
            x = 2 * x - 1
        
        # é€å—æå–ç‰¹å¾
        outputs = []
        for idx, block in enumerate(self.blocks):
            x = block(x)
            if idx in self.output_blocks:
                outputs.append(x)
        
        return outputs


class ImageDataset(Dataset):
    """å›¾åƒæ•°æ®é›†åŠ è½½å™¨"""
    
    def __init__(self, image_dir: Path, exts: set[str], transform=None):
        self.image_dir = image_dir
        self.transform = transform
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        self.image_files = sorted([
            f for f in image_dir.iterdir() 
            if f.is_file() and f.suffix.lower() in exts
        ])
        
        if not self.image_files:
            raise ValueError(f"âŒ åœ¨ {image_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        try:
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img
        except Exception as e:
            raise RuntimeError(f"âŒ è¯»å–å›¾åƒå¤±è´¥: {img_path}, é”™è¯¯: {e}")


def get_activations(image_dir: Path, model: nn.Module, batch_size: int, 
                   dims: int, num_workers: int, device: str, exts: set[str]):
    """
    è®¡ç®—å›¾åƒçš„Inceptionç‰¹å¾æ¿€æ´»å€¼
    
    Args:
        image_dir: å›¾åƒç›®å½•
        model: InceptionV3æ¨¡å‹
        batch_size: æ‰¹å¤§å°
        dims: ç‰¹å¾ç»´åº¦
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        device: è®¡ç®—è®¾å¤‡
        exts: å›¾åƒæ‰©å±•åé›†åˆ
    
    Returns:
        activations: (N, dims) çš„ç‰¹å¾æ•°ç»„
    """
    model.eval()
    
    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
    ])
    
    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    dataset = ImageDataset(image_dir, exts, transform=transform)
    dataloader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True if device == 'cuda' else False
    )
    
    print(f"ğŸ“ æ‰¾åˆ° {len(dataset)} å¼ å›¾åƒ")
    
    # æå–ç‰¹å¾
    activations = []
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="ğŸ“Š æå–ç‰¹å¾", unit="batch"):
            batch = batch.to(device)
            features = model(batch)[0]
            
            # å±•å¹³ç‰¹å¾
            if features.size(2) != 1 or features.size(3) != 1:
                features = F.adaptive_avg_pool2d(features, output_size=(1, 1))
            
            features = features.squeeze(3).squeeze(2)
            activations.append(features.cpu().numpy())
    
    activations = np.concatenate(activations, axis=0)
    
    # éªŒè¯ç»´åº¦
    if activations.shape[1] != dims:
        raise ValueError(f"âŒ ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ› {dims}, å¾—åˆ° {activations.shape[1]}")
    
    return activations


def calculate_activation_statistics(activations: np.ndarray):
    """
    è®¡ç®—æ¿€æ´»å€¼çš„å‡å€¼å’Œåæ–¹å·®çŸ©é˜µ
    
    Args:
        activations: (N, dims) çš„ç‰¹å¾æ•°ç»„
    
    Returns:
        mu: å‡å€¼å‘é‡
        sigma: åæ–¹å·®çŸ©é˜µ
    """
    mu = np.mean(activations, axis=0)
    sigma = np.cov(activations, rowvar=False)
    return mu, sigma


def calculate_frechet_distance(mu1: np.ndarray, sigma1: np.ndarray, 
                               mu2: np.ndarray, sigma2: np.ndarray, 
                               eps=1e-6):
    """
    è®¡ç®—ä¸¤ä¸ªå¤šå…ƒé«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„FrÃ©chetè·ç¦»
    
    FID = ||mu1 - mu2||^2 + Tr(sigma1 + sigma2 - 2*sqrt(sigma1*sigma2))
    
    Args:
        mu1: ç¬¬ä¸€ä¸ªåˆ†å¸ƒçš„å‡å€¼
        sigma1: ç¬¬ä¸€ä¸ªåˆ†å¸ƒçš„åæ–¹å·®çŸ©é˜µ
        mu2: ç¬¬äºŒä¸ªåˆ†å¸ƒçš„å‡å€¼
        sigma2: ç¬¬äºŒä¸ªåˆ†å¸ƒçš„åæ–¹å·®çŸ©é˜µ
        eps: æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°
    
    Returns:
        fid_score: FIDåˆ†æ•°
    """
    mu1 = np.atleast_1d(mu1)
    mu2 = np.atleast_1d(mu2)
    
    sigma1 = np.atleast_2d(sigma1)
    sigma2 = np.atleast_2d(sigma2)
    
    assert mu1.shape == mu2.shape, "å‡å€¼å‘é‡ç»´åº¦ä¸ä¸€è‡´"
    assert sigma1.shape == sigma2.shape, "åæ–¹å·®çŸ©é˜µç»´åº¦ä¸ä¸€è‡´"
    
    # è®¡ç®—å‡å€¼å·®çš„å¹³æ–¹
    diff = mu1 - mu2
    
    # è®¡ç®—åæ–¹å·®çŸ©é˜µçš„ä¹˜ç§¯å¹³æ–¹æ ¹
    # ä½¿ç”¨æ•°å€¼ç¨³å®šçš„æ–¹å¼
    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
    
    # å¤„ç†æ•°å€¼è¯¯å·®å¯¼è‡´çš„è™šéƒ¨
    if np.iscomplexobj(covmean):
        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
            m = np.max(np.abs(covmean.imag))
            raise ValueError(f"âš ï¸  åæ–¹å·®çŸ©é˜µä¹˜ç§¯å¹³æ–¹æ ¹åŒ…å«æ˜¾è‘—è™šéƒ¨ (max={m})")
        covmean = covmean.real
    
    # è®¡ç®—FID
    fid = diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * np.trace(covmean)
    
    return float(fid)


def compute_fid(real_path: Path, fake_path: Path, batch_size: int, 
               device: str, dims: int, num_workers: int, exts: set[str]):
    """
    è®¡ç®—FIDåˆ†æ•°
    
    Args:
        real_path: çœŸå®å›¾åƒç›®å½•
        fake_path: ç”Ÿæˆå›¾åƒç›®å½•
        batch_size: æ‰¹å¤§å°
        device: è®¡ç®—è®¾å¤‡
        dims: ç‰¹å¾ç»´åº¦
        num_workers: çº¿ç¨‹æ•°
        exts: å›¾åƒæ‰©å±•åé›†åˆ
    
    Returns:
        fid_score: FIDåˆ†æ•°
    """
    # ç¡®å®šä½¿ç”¨çš„blockç´¢å¼•
    block_idx_map = {64: 0, 192: 1, 768: 2, 2048: 3}
    if dims not in block_idx_map:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„ç‰¹å¾ç»´åº¦: {dims}, æ”¯æŒçš„ç»´åº¦: {list(block_idx_map.keys())}")
    
    block_idx = block_idx_map[dims]
    
    print(f"ğŸ”§ åˆå§‹åŒ– InceptionV3 æ¨¡å‹ (ç‰¹å¾ç»´åº¦: {dims})...")
    model = InceptionV3Feature(output_blocks=[block_idx], resize_input=True, normalize_input=True)
    model = model.to(device)
    
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æå–çœŸå®å›¾åƒç‰¹å¾
    print("\nğŸ“¸ å¤„ç†çœŸå®å›¾åƒ...")
    real_activations = get_activations(
        real_path, model, batch_size, dims, num_workers, device, exts
    )
    
    # æå–ç”Ÿæˆå›¾åƒç‰¹å¾
    print("\nğŸ¨ å¤„ç†ç”Ÿæˆå›¾åƒ...")
    fake_activations = get_activations(
        fake_path, model, batch_size, dims, num_workers, device, exts
    )
    
    # è®¡ç®—ç»Ÿè®¡é‡
    print("\nğŸ“Š è®¡ç®—ç»Ÿè®¡é‡...")
    mu_real, sigma_real = calculate_activation_statistics(real_activations)
    mu_fake, sigma_fake = calculate_activation_statistics(fake_activations)
    
    # è®¡ç®—FID
    print("ğŸ§® è®¡ç®— FID åˆ†æ•°...")
    fid_score = calculate_frechet_distance(mu_real, sigma_real, mu_fake, sigma_fake)
    
    return fid_score


def main():
    """ä¸»å‡½æ•°"""
    # éªŒè¯è·¯å¾„
    real_path = Path(REAL_PATH)
    fake_path = Path(FAKE_PATH)
    
    if not real_path.exists():
        print(f"âŒ çœŸå®å›¾åƒè·¯å¾„ä¸å­˜åœ¨: {real_path}")
        print(f"ğŸ’¡ è¯·å°† REAL_PATH å˜é‡è®¾ç½®ä¸ºæ­£ç¡®çš„è·¯å¾„")
        return
    
    if not fake_path.exists():
        print(f"âŒ ç”Ÿæˆå›¾åƒè·¯å¾„ä¸å­˜åœ¨: {fake_path}")
        print(f"ğŸ’¡ è¯·å°† FAKE_PATH å˜é‡è®¾ç½®ä¸ºæ­£ç¡®çš„è·¯å¾„")
        return
    
    if not real_path.is_dir() or not fake_path.is_dir():
        print("âŒ REAL_PATH å’Œ FAKE_PATH å¿…é¡»éƒ½æ˜¯ç›®å½•")
        return
    
    # è§£ææ‰©å±•å
    exts = {f".{e.strip().lower()}" for e in EXTS.replace('.', '').split(',') if e.strip()}
    
    print("=" * 60)
    print("ğŸ¯ FID (FrÃ©chet Inception Distance) è¯„ä¼°")
    print("=" * 60)
    print(f"ğŸ“ çœŸå®å›¾åƒç›®å½•: {real_path}")
    print(f"ğŸ“ ç”Ÿæˆå›¾åƒç›®å½•: {fake_path}")
    print(f"ğŸ”¢ æ‰¹å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ§µ å·¥ä½œçº¿ç¨‹æ•°: {NUM_WORKERS}")
    print(f"ğŸ“ ç‰¹å¾ç»´åº¦: {DIMS}")
    print("=" * 60)
    
    try:
        fid_score = compute_fid(
            real_path=real_path,
            fake_path=fake_path,
            batch_size=BATCH_SIZE,
            device=DEVICE,
            dims=DIMS,
            num_workers=NUM_WORKERS,
            exts=exts
        )
        
        print("\n" + "=" * 60)
        print(f"âœ¨ FID åˆ†æ•°: {fid_score:.4f}")
        print("=" * 60)
        print("\nğŸ’¡ FID è§£è¯»:")
        print("  â€¢ FID å€¼è¶Šå°è¶Šå¥½")
        print("  â€¢ FID < 50: ä¼˜ç§€")
        print("  â€¢ FID 50-100: è‰¯å¥½")
        print("  â€¢ FID 100-200: ä¸€èˆ¬")
        print("  â€¢ FID > 200: éœ€è¦æ”¹è¿›")
        print("\nâœ¨ è¯„ä¼°å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

