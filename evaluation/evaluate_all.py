"""
å›¾åƒè´¨é‡è¯„ä¼°å…¨æµç¨‹å·¥å…·
é›†æˆ PSNR/SSIM è®¡ç®—ã€ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½
ä¸€æ­¥åˆ°ä½å®Œæˆä»è¯„ä¼°åˆ°å¯è§†åŒ–çš„å…¨éƒ¨æµç¨‹
"""

import csv
import math
import os
import functools
from pathlib import Path
from typing import Optional, Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor

import cv2
import numpy as np

# ============== é…ç½®å‚æ•° ==============
# è·¯å¾„é…ç½®
REF_PATH = "/home/lzh/myCode/awesome-virtual-staining/datasets/ttc1/test_latest/images/real_B"
PRED_PATH = "/home/lzh/myCode/awesome-virtual-staining/datasets/ttc1/test_latest/images/fake_B"
OUTPUT_DIR = "/home/lzh/myCode/awesome-virtual-staining/datasets/ttc1/test_latest"
# è¯„ä¼°å‚æ•°
GRAYSCALE = False  # æ˜¯å¦ä»¥ç°åº¦æ¨¡å¼è¯„ä¼°
RESIZE = True  # è‹¥å°ºå¯¸ä¸åŒæ˜¯å¦è‡ªåŠ¨ç¼©æ”¾
EXTS = ".png,.jpg,.jpeg,.tif,.tiff"  # åŒ¹é…çš„å›¾åƒæ‰©å±•å
DATA_RANGE = None  # åƒç´ åŠ¨æ€èŒƒå›´ï¼ˆNoneä¸ºè‡ªåŠ¨æ¨æ–­ï¼‰
THREADS = os.cpu_count() or 4  # ä½¿ç”¨çš„çº¿ç¨‹æ•°

# è¾“å‡ºé…ç½®
SAVE_CSV = True  # æ˜¯å¦ä¿å­˜è¯¦ç»†CSVç»“æœ
SAVE_SUMMARY = True  # æ˜¯å¦ä¿å­˜ç»Ÿè®¡æ‘˜è¦
ENABLE_PLOT = True  # æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
SHOW_PLOTS = False  # æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨ï¼ˆFalseåˆ™åªä¿å­˜ï¼‰
# ======================================

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    from skimage.metrics import structural_similarity as ssim
except Exception as e:
    raise RuntimeError("âŒ è¯·å®‰è£… scikit-image: pip install scikit-image") from e

try:
    from tqdm import tqdm
except ImportError:
    raise RuntimeError("âŒ è¯·å®‰è£… tqdm: pip install tqdm")

try:
    import matplotlib
    if not SHOW_PLOTS:
        matplotlib.use('Agg')  # ä¸æ˜¾ç¤ºå›¾å½¢ç•Œé¢
    import matplotlib.pyplot as plt
    HAS_PLOTTING = True
except ImportError:
    HAS_PLOTTING = False
    print("âš ï¸  matplotlib æœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§†åŒ–åŠŸèƒ½")


# ==================== PSNR/SSIM è®¡ç®—æ¨¡å— ====================

def compute_psnr(ref_img: np.ndarray, pred_img: np.ndarray, data_range: float) -> float:
    """è®¡ç®—PSNRå€¼"""
    diff = ref_img.astype(np.float32) - pred_img.astype(np.float32)
    mse = np.mean(diff ** 2, dtype=np.float64)
    if mse == 0:
        return float("inf")
    return 20.0 * math.log10(data_range) - 10.0 * math.log10(mse)


def compute_ssim(ref_img: np.ndarray, pred_img: np.ndarray, data_range: float) -> float:
    """è®¡ç®—SSIMå€¼"""
    try:
        return ssim(
            ref_img, pred_img, data_range=data_range,
            channel_axis=-1 if ref_img.ndim == 3 else None,
            gaussian_weights=True, sigma=1.5, use_sample_covariance=False,
        )
    except TypeError:
        return ssim(
            ref_img, pred_img, data_range=data_range,
            multichannel=(ref_img.ndim == 3), gaussian_weights=True, sigma=1.5,
            use_sample_covariance=False,
        )


def read_image(path: Path, grayscale: bool) -> np.ndarray:
    """è¯»å–å›¾åƒ"""
    if grayscale:
        img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)
    else:
        img = cv2.imread(str(path), cv2.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"æ— æ³•è¯»å–å›¾åƒ: {path}")
    return img


def prepare_pair(
    ref_path: Path, pred_path: Path, grayscale: bool, resize: bool,
) -> tuple[np.ndarray, np.ndarray]:
    """å‡†å¤‡å›¾åƒå¯¹ï¼Œå¿…è¦æ—¶è¿›è¡Œå°ºå¯¸è°ƒæ•´"""
    ref = read_image(ref_path, grayscale)
    pred = read_image(pred_path, grayscale)
    if ref.shape != pred.shape:
        if not resize:
            raise ValueError(
                f"å°ºå¯¸ä¸ä¸€è‡´: {ref_path.name} {ref.shape} vs {pred_path.name} {pred.shape}"
            )
        h, w = ref.shape[:2]
        interp = cv2.INTER_AREA if pred.shape[1] * pred.shape[0] >= w * h else cv2.INTER_CUBIC
        pred = cv2.resize(pred, (w, h), interpolation=interp)
    return ref, pred


def determine_data_range(img: np.ndarray, user_range: Optional[float]) -> float:
    """ç¡®å®šæ•°æ®èŒƒå›´"""
    if user_range is not None:
        return float(user_range)
    if img.dtype == np.uint8:
        return 255.0
    if img.dtype == np.uint16:
        return 65535.0
    max_val = float(np.max(img))
    min_val = float(np.min(img))
    return max(1e-6, max_val - min_val)


def is_image_file(p: Path, exts: set[str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶"""
    return p.is_file() and p.suffix.lower() in exts


def collect_pairs(ref_dir: Path, pred_dir: Path, exts: set[str]) -> list[tuple[Path, Path]]:
    """æ”¶é›†åŒ¹é…çš„å›¾åƒå¯¹"""
    ref_files = [p for p in ref_dir.iterdir() if is_image_file(p, exts)]
    pred_files = [p for p in pred_dir.iterdir() if is_image_file(p, exts)]
    ref_map = {p.name: p for p in ref_files}
    pred_map = {p.name: p for p in pred_files}
    common_filenames = sorted(set(ref_map.keys()) & set(pred_map.keys()))
    return [(ref_map[name], pred_map[name]) for name in common_filenames]


def process_one_pair(pair: tuple[Path, Path], grayscale: bool, resize: bool, data_range: Optional[float]) -> dict:
    """å¤„ç†å•å¯¹å›¾åƒçš„å‡½æ•°"""
    ref_path, pred_path = pair
    try:
        ref_img, pred_img = prepare_pair(ref_path, pred_path, grayscale, resize)
        dr = determine_data_range(ref_img, data_range)
        psnr_val = compute_psnr(ref_img, pred_img, dr)
        ssim_val = compute_ssim(ref_img, pred_img, dr)
        h, w = ref_img.shape[:2]
        return {
            'filename': ref_path.name,
            'width': w,
            'height': h,
            'psnr': psnr_val,
            'ssim': ssim_val,
            'success': True
        }
    except Exception as e:
        return {
            'filename': ref_path.name,
            'width': None,
            'height': None,
            'psnr': None,
            'ssim': None,
            'success': False,
            'error': f"{type(e).__name__}: {e}"
        }


# ==================== ç»Ÿè®¡åˆ†ææ¨¡å— ====================

class MetricsAnalyzer:
    """è¯„ä¼°æŒ‡æ ‡åˆ†æå™¨"""
    
    def __init__(self, results: List[dict]):
        self.results = results
        self.valid_results = [r for r in results if r['success']]
        # æå–PSNRå’ŒSSIMæ•°ç»„
        if self.valid_results:
            self.psnr_array = np.array([r['psnr'] for r in self.valid_results])
            self.ssim_array = np.array([r['ssim'] for r in self.valid_results])
        else:
            self.psnr_array = np.array([])
            self.ssim_array = np.array([])
    
    def basic_statistics(self) -> Dict:
        """è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯"""
        if len(self.psnr_array) == 0:
            return {}
        
        stats_dict = {
            'count': len(self.psnr_array),
            'psnr': {
                'mean': float(np.mean(self.psnr_array)),
                'std': float(np.std(self.psnr_array)),
                'min': float(np.min(self.psnr_array)),
                'max': float(np.max(self.psnr_array)),
                'median': float(np.median(self.psnr_array)),
                'q25': float(np.percentile(self.psnr_array, 25)),
                'q75': float(np.percentile(self.psnr_array, 75))
            },
            'ssim': {
                'mean': float(np.mean(self.ssim_array)),
                'std': float(np.std(self.ssim_array)),
                'min': float(np.min(self.ssim_array)),
                'max': float(np.max(self.ssim_array)),
                'median': float(np.median(self.ssim_array)),
                'q25': float(np.percentile(self.ssim_array, 25)),
                'q75': float(np.percentile(self.ssim_array, 75))
            }
        }
        
        return stats_dict
    
    def quality_distribution(self) -> Dict:
        """åˆ†æè´¨é‡åˆ†å¸ƒ"""
        if len(self.psnr_array) == 0:
            return {}
        
        # PSNRè´¨é‡åˆ†çº§
        psnr_excellent = np.sum(self.psnr_array >= 40)
        psnr_good = np.sum((self.psnr_array >= 30) & (self.psnr_array < 40))
        psnr_fair = np.sum((self.psnr_array >= 20) & (self.psnr_array < 30))
        psnr_poor = np.sum(self.psnr_array < 20)
        
        # SSIMè´¨é‡åˆ†çº§
        ssim_excellent = np.sum(self.ssim_array >= 0.9)
        ssim_good = np.sum((self.ssim_array >= 0.8) & (self.ssim_array < 0.9))
        ssim_fair = np.sum((self.ssim_array >= 0.7) & (self.ssim_array < 0.8))
        ssim_poor = np.sum(self.ssim_array < 0.7)
        
        total = len(self.psnr_array)
        
        return {
            'psnr_distribution': {
                'excellent (â‰¥40dB)': {'count': psnr_excellent, 'percentage': psnr_excellent/total*100},
                'good (30-40dB)': {'count': psnr_good, 'percentage': psnr_good/total*100},
                'fair (20-30dB)': {'count': psnr_fair, 'percentage': psnr_fair/total*100},
                'poor (<20dB)': {'count': psnr_poor, 'percentage': psnr_poor/total*100}
            },
            'ssim_distribution': {
                'excellent (â‰¥0.9)': {'count': ssim_excellent, 'percentage': ssim_excellent/total*100},
                'good (0.8-0.9)': {'count': ssim_good, 'percentage': ssim_good/total*100},
                'fair (0.7-0.8)': {'count': ssim_fair, 'percentage': ssim_fair/total*100},
                'poor (<0.7)': {'count': ssim_poor, 'percentage': ssim_poor/total*100}
            }
        }
    
    def print_statistics(self, stats_dict: Dict):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if not stats_dict:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯åˆ†æ")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š PSNR/SSIM ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        print(f"\nğŸ“ˆ æ•°æ®æ¦‚è§ˆ:")
        print(f"   æ€»è®°å½•æ•°: {stats_dict['count']}")
        if len(self.results) - stats_dict['count'] > 0:
            print(f"   å¤±è´¥è®°å½•: {len(self.results) - stats_dict['count']}")
        
        print(f"\nğŸ¯ PSNR ç»Ÿè®¡ (dB):")
        psnr = stats_dict['psnr']
        print(f"   å¹³å‡å€¼: {psnr['mean']:.4f}")
        print(f"   æ ‡å‡†å·®: {psnr['std']:.4f}")
        print(f"   ä¸­ä½æ•°: {psnr['median']:.4f}")
        print(f"   æœ€å°å€¼: {psnr['min']:.4f}")
        print(f"   æœ€å¤§å€¼: {psnr['max']:.4f}")
        print(f"   25åˆ†ä½æ•°: {psnr['q25']:.4f}")
        print(f"   75åˆ†ä½æ•°: {psnr['q75']:.4f}")
        
        print(f"\nğŸ¯ SSIM ç»Ÿè®¡:")
        ssim_stats = stats_dict['ssim']
        print(f"   å¹³å‡å€¼: {ssim_stats['mean']:.6f}")
        print(f"   æ ‡å‡†å·®: {ssim_stats['std']:.6f}")
        print(f"   ä¸­ä½æ•°: {ssim_stats['median']:.6f}")
        print(f"   æœ€å°å€¼: {ssim_stats['min']:.6f}")
        print(f"   æœ€å¤§å€¼: {ssim_stats['max']:.6f}")
        print(f"   25åˆ†ä½æ•°: {ssim_stats['q25']:.6f}")
        print(f"   75åˆ†ä½æ•°: {ssim_stats['q75']:.6f}")
    
    def print_quality_distribution(self, dist_dict: Dict):
        """æ‰“å°è´¨é‡åˆ†å¸ƒ"""
        if not dist_dict:
            return
        
        print(f"\nğŸ“Š è´¨é‡åˆ†å¸ƒåˆ†æ:")
        print(f"\nğŸ¯ PSNR è´¨é‡åˆ†å¸ƒ:")
        for level, info in dist_dict['psnr_distribution'].items():
            print(f"   {level}: {info['count']} å¼ å›¾åƒ ({info['percentage']:.1f}%)")
        
        print(f"\nğŸ¯ SSIM è´¨é‡åˆ†å¸ƒ:")
        for level, info in dist_dict['ssim_distribution'].items():
            print(f"   {level}: {info['count']} å¼ å›¾åƒ ({info['percentage']:.1f}%)")

# ==================== è¾“å‡ºæ¨¡å— ====================

def save_csv_results(results: List[dict], output_path: Path):
    """ä¿å­˜è¯¦ç»†çš„CSVç»“æœ"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["filename", "width", "height", "psnr", "ssim"])
        for res in results:
            if res['success']:
                writer.writerow([
                    res['filename'], 
                    res['width'], 
                    res['height'], 
                    f"{res['psnr']:.6f}", 
                    f"{res['ssim']:.6f}"
                ])
            else:
                writer.writerow([
                    res['filename'], 
                    "-", 
                    "-", 
                    "ERROR", 
                    res.get('error', 'Unknown error')
                ])
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {output_path}")


def save_summary(stats_dict: Dict, dist_dict: Dict, output_path: Path):
    """ä¿å­˜ç»Ÿè®¡æ‘˜è¦"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("PSNR/SSIM Statistical Analysis Report\n")
        f.write("="*60 + "\n\n")
        
        f.write(f"Data Overview:\n")
        f.write(f"  Total records: {stats_dict.get('count', 0)}\n\n")
        
        f.write("PSNR Statistics (dB):\n")
        psnr = stats_dict.get('psnr', {})
        for key, value in psnr.items():
            f.write(f"  {key}: {value:.4f}\n")
        
        f.write("\nSSIM Statistics:\n")
        ssim_stats = stats_dict.get('ssim', {})
        for key, value in ssim_stats.items():
            f.write(f"  {key}: {value:.6f}\n")
        
        f.write("\n" + "="*60 + "\n")
        f.write("Quality Distribution:\n")
        f.write("="*60 + "\n\n")
        if dist_dict:
            f.write("PSNR Quality Distribution:\n")
            for level, info in dist_dict['psnr_distribution'].items():
                f.write(f"  {level}: {info['count']} images ({info['percentage']:.1f}%)\n")
            
            f.write("\nSSIM Quality Distribution:\n")
            for level, info in dist_dict['ssim_distribution'].items():
                f.write(f"  {level}: {info['count']} images ({info['percentage']:.1f}%)\n")
    
    print(f"ğŸ“„ ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜è‡³: {output_path}")


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ¯ å›¾åƒè´¨é‡è¯„ä¼°å…¨æµç¨‹å·¥å…·")
    print("="*60)
    
    # è·¯å¾„éªŒè¯
    ref_path = Path(REF_PATH)
    pred_path = Path(PRED_PATH)
    output_dir = Path(OUTPUT_DIR)
    
    if not ref_path.exists():
        print(f"âŒ å‚è€ƒè·¯å¾„ä¸å­˜åœ¨: {ref_path}")
        return
    
    if not pred_path.exists():
        print(f"âŒ é¢„æµ‹è·¯å¾„ä¸å­˜åœ¨: {pred_path}")
        return
    
    if not (ref_path.is_dir() and pred_path.is_dir()):
        print("âŒ è·¯å¾„å¿…é¡»ä¸ºç›®å½•")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“ å‚è€ƒå›¾åƒ: {ref_path}")
    print(f"ğŸ“ é¢„æµ‹å›¾åƒ: {pred_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("="*60)
    
    # æ­¥éª¤1: è®¡ç®—PSNR/SSIM
    print("\nã€æ­¥éª¤ 1/3ã€‘è®¡ç®— PSNR/SSIM æŒ‡æ ‡")
    print("-"*60)
    
    exts = {f".{e.strip().lower()}" for e in EXTS.replace('.', '').split(',') if e.strip()}
    pairs = collect_pairs(ref_path, pred_path, exts)
    
    if not pairs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯åŒ¹é…çš„å›¾åƒå¯¹")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(pairs)} å¯¹å¯åŒ¹é…çš„å›¾åƒ")
    
    task_processor = functools.partial(
        process_one_pair,
        grayscale=GRAYSCALE,
        resize=RESIZE,
        data_range=DATA_RANGE
    )
    
    results = []
    print(f"ğŸš€ ä½¿ç”¨ {THREADS} ä¸ªçº¿ç¨‹å¼€å§‹å¤„ç†...")
    with ThreadPoolExecutor(max_workers=THREADS) as executor:
        results_iterator = executor.map(task_processor, pairs)
        results = list(tqdm(results_iterator, total=len(pairs), desc="ğŸ“Š è®¡ç®—è¿›åº¦", unit="å¼ "))
    
    # æ­¥éª¤2: ç»Ÿè®¡åˆ†æ
    print("\nã€æ­¥éª¤ 2/3ã€‘ç»Ÿè®¡åˆ†æ")
    print("-"*60)
    
    analyzer = MetricsAnalyzer(results)
    stats_dict = analyzer.basic_statistics()
    dist_dict = analyzer.quality_distribution()
    
    analyzer.print_statistics(stats_dict)
    analyzer.print_quality_distribution(dist_dict)
    
    # æ­¥éª¤3: ç”Ÿæˆè¾“å‡º
    print("\nã€æ­¥éª¤ 3/3ã€‘ç”Ÿæˆè¾“å‡ºæ–‡ä»¶")
    print("-"*60)
    
    if SAVE_CSV:
        save_csv_results(results, output_dir / "results.csv")
    
    if SAVE_SUMMARY:
        save_summary(stats_dict, dist_dict, output_dir / "summary.txt")
    
    if ENABLE_PLOT and HAS_PLOTTING and len(analyzer.psnr_array) > 0:
        create_visualizations(analyzer.psnr_array, analyzer.ssim_array, output_dir)
    elif ENABLE_PLOT and not HAS_PLOTTING:
        print("âš ï¸  å·²è·³è¿‡å¯è§†åŒ–ï¼ˆmatplotlibä¸å¯ç”¨ï¼‰")
    
    print("\n" + "="*60)
    print("âœ¨ å…¨æµç¨‹è¯„ä¼°å®Œæˆï¼")
    print("="*60)
    print(f"\nğŸ“‚ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
    print(f"   â€¢ results.csv - è¯¦ç»†æ•°æ®")
    print(f"   â€¢ summary.txt - ç»Ÿè®¡æ‘˜è¦")
    if ENABLE_PLOT and HAS_PLOTTING:
        print(f"   â€¢ *.png - å¯è§†åŒ–å›¾è¡¨ (5å¼ )")
    print()


if __name__ == "__main__":
    main()

